{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This file is for programming regist\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click !here goes the icon of the corresponding button in the gutter! button.\n",
    "To debug a cell, press Alt+Shift+Enter, or click !here goes the icon of the corresponding button in the gutter! button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/jupyter-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import igl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from hilbertcurve.hilbertcurve import HilbertCurve\n",
    "\n",
    "# 定义文件路径\n",
    "input_file = os.path.join(\"data\", \"body0.obj\")\n",
    "\n",
    "# 读取 OBJ 文件\n",
    "V, F = igl.read_triangle_mesh(input_file)\n",
    "\n",
    "# 使用 KMeans 进行聚类 (假设我们想要 200 个 cluster)\n",
    "num_clusters = 256\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "face_centers = np.mean(V[F], axis=1)\n",
    "kmeans.fit(face_centers)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# 找到每个顶点的相邻三角形\n",
    "vertex_faces = defaultdict(set)\n",
    "for i, face in enumerate(F):\n",
    "    for vertex in face:\n",
    "        vertex_faces[vertex].add(i)\n",
    "\n",
    "# 计算每个 cluster 的重心\n",
    "cluster_centroids = []\n",
    "for i in range(num_clusters):\n",
    "    cluster_vertices = V[F[labels == i]].reshape(-1, 3)\n",
    "    centroid = np.mean(cluster_vertices, axis=0)\n",
    "    cluster_centroids.append(centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# 将重心归一化到 [0, 1] 范围内，然后转换为 [0, 2^p-1] 范围内的整数\n",
    "p = 10  # 设置Hilbert曲线的阶数\n",
    "hilbert_max = 2**p - 1\n",
    "min_coords = np.min(cluster_centroids, axis=0)\n",
    "max_coords = np.max(cluster_centroids, axis=0)\n",
    "norm_centroids = (cluster_centroids - min_coords) / (max_coords - min_coords) * hilbert_max\n",
    "norm_centroids = norm_centroids.astype(int)\n",
    "\n",
    "# 计算Hilbert编码\n",
    "hilbert_curve = HilbertCurve(p, 3)\n",
    "hilbert_indices = [hilbert_curve.distance_from_point(c.tolist()) for c in norm_centroids]\n",
    "sorted_indices = np.argsort(hilbert_indices)\n",
    "\n",
    "# 可视化每个 cluster\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = plt.cm.get_cmap('hsv', num_clusters)\n",
    "\n",
    "for idx in sorted_indices:\n",
    "    cluster_faces = F[labels == idx]\n",
    "    cluster_vertices_indices = np.unique(cluster_faces)\n",
    "    cluster_vertices = V[cluster_vertices_indices]\n",
    "\n",
    "    new_indices = {old_idx: new_idx for new_idx, old_idx in enumerate(cluster_vertices_indices)}\n",
    "    cluster_faces_new = np.vectorize(new_indices.get)(cluster_faces)\n",
    "\n",
    "    patch_mesh = Poly3DCollection(cluster_vertices[cluster_faces_new], alpha=0.5, facecolors=colors(idx))\n",
    "    patch_mesh.set_edgecolor('k')\n",
    "    ax.add_collection3d(patch_mesh)\n",
    "\n",
    "# 设置坐标范围\n",
    "scale = V.flatten()\n",
    "ax.auto_scale_xyz(scale, scale, scale)\n",
    "\n",
    "# 设置视角\n",
    "ax.view_init(30, 30)\n",
    "\n",
    "# 显示图形\n",
    "plt.show()\n",
    "\n",
    "# 输出目录\n",
    "output_dir = \"output_clusters\"\n",
    "regist_dir = \"regist_file\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(regist_dir, exist_ok=True)\n",
    "\n",
    "# 准备CSV数据\n",
    "cluster_vertices_list = []\n",
    "extended_cluster_vertices_list = []\n",
    "\n",
    "# 将每个 cluster 及其扩展层保存为新的 OBJ 文件\n",
    "for sorted_idx, idx in enumerate(sorted_indices):\n",
    "    cluster_faces = F[labels == idx]\n",
    "    cluster_vertices_indices = np.unique(cluster_faces)\n",
    "    cluster_vertices = V[cluster_vertices_indices]\n",
    "\n",
    "    new_indices = {old_idx: new_idx for new_idx, old_idx in enumerate(cluster_vertices_indices)}\n",
    "    cluster_faces_new = np.vectorize(new_indices.get)(cluster_faces)\n",
    "\n",
    "    # 保存聚类的原始OBJ\n",
    "    output_filename = os.path.join(output_dir, f\"cluster_{sorted_idx}.obj\")\n",
    "    igl.write_triangle_mesh(output_filename, cluster_vertices, cluster_faces_new)\n",
    "    print(f\"Cluster {sorted_idx} saved to {output_filename}\")\n",
    "\n",
    "    # 保存聚类内的顶点索引到列表\n",
    "    cluster_vertices_list.append(cluster_vertices_indices)\n",
    "\n",
    "    # 找到扩展层的三角形\n",
    "    extended_faces = set()\n",
    "    for face_idx in np.where(labels == idx)[0]:\n",
    "        # 找到所有与该face共享顶点的三角形\n",
    "        for vertex in F[face_idx]:\n",
    "            extended_faces.update(vertex_faces[vertex])\n",
    "    extended_faces.difference_update(np.where(labels == idx)[0])  # 移除原始聚类的三角形\n",
    "    extended_faces = np.array(list(extended_faces))\n",
    "\n",
    "    if len(extended_faces) > 0:\n",
    "        extended_cluster_faces = F[extended_faces]\n",
    "        extended_cluster_vertices_indices = np.unique(extended_cluster_faces)\n",
    "        extended_cluster_vertices = V[extended_cluster_vertices_indices]\n",
    "\n",
    "        new_indices_ext = {old_idx: new_idx for new_idx, old_idx in enumerate(extended_cluster_vertices_indices)}\n",
    "        extended_cluster_faces_new = np.vectorize(new_indices_ext.get)(extended_cluster_faces)\n",
    "\n",
    "        # 保存扩展层的OBJ\n",
    "        extended_output_filename = os.path.join(output_dir, f\"extended_cluster_{sorted_idx}.obj\")\n",
    "        igl.write_triangle_mesh(extended_output_filename, extended_cluster_vertices, extended_cluster_faces_new)\n",
    "        print(f\"Extended Cluster {sorted_idx} saved to {extended_output_filename}\")\n",
    "\n",
    "        # 保存扩展层顶点索引到列表\n",
    "        extended_cluster_vertices_list.append(np.unique(np.concatenate((cluster_vertices_indices, extended_cluster_vertices_indices))))\n",
    "    else:\n",
    "        print(f\"No extended faces found for cluster {sorted_idx}\")\n",
    "        # 如果没有扩展层，则仅保存原始聚类的顶点索引\n",
    "        extended_cluster_vertices_list.append(cluster_vertices_indices)\n",
    "\n",
    "# 导出聚类顶点索引的CSV文件\n",
    "cluster_vertices_file = os.path.join(regist_dir, \"cluster_vertices.csv\")\n",
    "with open(cluster_vertices_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for indices in cluster_vertices_list:\n",
    "        writer.writerow(indices)\n",
    "print(f\"Cluster vertices saved to {cluster_vertices_file}\")\n",
    "\n",
    "# 导出扩展层顶点索引的CSV文件\n",
    "extended_cluster_vertices_file = os.path.join(regist_dir, \"extended_cluster_vertices.csv\")\n",
    "with open(extended_cluster_vertices_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for indices in extended_cluster_vertices_list:\n",
    "        writer.writerow(indices)\n",
    "print(f\"Extended cluster vertices saved to {extended_cluster_vertices_file}\")\n"
   ],
   "id": "93c3ea81c020d9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_skeleton(file_path):\n",
    "    vertices = []\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('v '):\n",
    "                vertices.append([float(x) for x in line.strip().split()[1:]])\n",
    "            elif line.startswith('l '):\n",
    "                edges.append([int(x) - 1 for x in line.strip().split()[1:]])  # indices are 1-based in OBJ\n",
    "    return np.array(vertices), np.array(edges)\n",
    "\n",
    "# 投影点计算\n",
    "def project_point_to_segment(p, v, w):\n",
    "    l2 = np.sum((v - w) ** 2)\n",
    "    if l2 == 0.0:\n",
    "        return v\n",
    "    t = max(0, min(1, np.dot(p - v, w - v) / l2))\n",
    "    projection = v + t * (w - v)\n",
    "    return projection\n",
    "\n",
    "# 计算每个 cluster 的重心\n",
    "cluster_centroids = []\n",
    "for i in sorted_indices:\n",
    "    cluster_vertices = V[F[labels == i]].reshape(-1, 3)\n",
    "    centroid = np.mean(cluster_vertices, axis=0)\n",
    "    cluster_centroids.append(centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "# 读取骨骼文件\n",
    "skeleton_file = os.path.join(\"data\", \"skeleton0.obj\")\n",
    "skeleton_vertices, skeleton_edges = read_skeleton(skeleton_file)\n",
    "\n",
    "# 计算每个 cluster 重心到骨骼的最近投影点\n",
    "projection_points = []\n",
    "projection_indices = []\n",
    "for centroid in cluster_centroids:\n",
    "    min_dist = float('inf')\n",
    "    nearest_projection = None\n",
    "    nearest_edge_idx = -1\n",
    "    for edge_idx, (start_idx, end_idx) in enumerate(skeleton_edges):\n",
    "        start_vertex = skeleton_vertices[start_idx]\n",
    "        end_vertex = skeleton_vertices[end_idx]\n",
    "        projection = project_point_to_segment(centroid, start_vertex, end_vertex)\n",
    "        dist = np.linalg.norm(centroid - projection)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            nearest_projection = projection\n",
    "            nearest_edge_idx = edge_idx\n",
    "    projection_points.append(nearest_projection)\n",
    "    projection_indices.append(nearest_edge_idx)\n",
    "\n",
    "# 输出 CSV 文件\n",
    "output_csv_file = os.path.join(regist_dir, \"projections.csv\")\n",
    "with open(output_csv_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for idx, (proj_point, proj_idx) in enumerate(zip(projection_points, projection_indices)):\n",
    "        writer.writerow([proj_idx, *proj_point])\n",
    "print(f\"Projections saved to {output_csv_file}\")\n",
    "\n",
    "# 生成连接重心和投影点的 OBJ 文件\n",
    "output_obj_file = os.path.join(regist_dir, \"centroids_to_projections.obj\")\n",
    "with open(output_obj_file, 'w') as f:\n",
    "    for i, (centroid, projection) in enumerate(zip(cluster_centroids, projection_points)):\n",
    "        f.write(f\"v {centroid[0]} {centroid[1]} {centroid[2]}\\n\")\n",
    "        f.write(f\"v {projection[0]} {projection[1]} {projection[2]}\\n\")\n",
    "    for i in range(len(cluster_centroids)):\n",
    "        f.write(f\"l {2*i+1} {2*i+2}\\n\")\n",
    "print(f\"Connections saved to {output_obj_file}\")"
   ],
   "id": "324244e8b9530267",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import igl\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "# 读取骨骼文件\n",
    "def read_skeleton(file_path):\n",
    "    vertices = []\n",
    "    edges = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('v '):\n",
    "                vertices.append([float(x) for x in line.strip().split()[1:]])\n",
    "            elif line.startswith('l '):\n",
    "                edges.append([int(x) - 1 for x in line.strip().split()[1:]])  # indices are 1-based in OBJ\n",
    "    return np.array(vertices), np.array(edges)\n",
    "\n",
    "# 投影点计算\n",
    "def project_point_to_segment(p, v, w):\n",
    "    l2 = np.sum((v - w) ** 2)\n",
    "    if l2 == 0.0:\n",
    "        return v\n",
    "    t = max(0, min(1, np.dot(p - v, w - v) / l2))\n",
    "    projection = v + t * (w - v)\n",
    "    return projection\n",
    "\n",
    "# 计算AABB的8个角顶点\n",
    "def compute_aabb(vertices):\n",
    "    min_corner = np.min(vertices, axis=0)\n",
    "    max_corner = np.max(vertices, axis=0)\n",
    "    return np.array([\n",
    "        [min_corner[0], min_corner[1], min_corner[2]],\n",
    "        [min_corner[0], min_corner[1], max_corner[2]],\n",
    "        [min_corner[0], max_corner[1], min_corner[2]],\n",
    "        [min_corner[0], max_corner[1], max_corner[2]],\n",
    "        [max_corner[0], min_corner[1], min_corner[2]],\n",
    "        [max_corner[0], min_corner[1], max_corner[2]],\n",
    "        [max_corner[0], max_corner[1], min_corner[2]],\n",
    "        [max_corner[0], max_corner[1], max_corner[2]]\n",
    "    ])\n",
    "\n",
    "# 计算每个 cluster 的 AABB\n",
    "aabb_corners = []\n",
    "for i in sorted_indices:\n",
    "    cluster_vertices = V[F[labels == i]].reshape(-1, 3)\n",
    "    corners = compute_aabb(cluster_vertices)\n",
    "    aabb_corners.append(corners)\n",
    "\n",
    "# 读取骨骼文件\n",
    "skeleton_file = os.path.join(\"data\", \"skeleton0.obj\")\n",
    "skeleton_vertices, skeleton_edges = read_skeleton(skeleton_file)\n",
    "\n",
    "# 计算每个 AABB 角顶点到骨骼的最近投影点\n",
    "projection_points = []\n",
    "projection_indices = []\n",
    "cluster_to_bone_map = defaultdict(set)\n",
    "bone_to_cluster_map = defaultdict(set)\n",
    "for cluster_idx, corners in enumerate(aabb_corners):\n",
    "    cluster_proj_points = []\n",
    "    for corner in corners:\n",
    "        min_dist = float('inf')\n",
    "        nearest_projection = None\n",
    "        nearest_edge_idx = -1\n",
    "        for edge_idx, (start_idx, end_idx) in enumerate(skeleton_edges):\n",
    "            start_vertex = skeleton_vertices[start_idx]\n",
    "            end_vertex = skeleton_vertices[end_idx]\n",
    "            projection = project_point_to_segment(corner, start_vertex, end_vertex)\n",
    "            dist = np.linalg.norm(corner - projection)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                nearest_projection = projection\n",
    "                nearest_edge_idx = edge_idx\n",
    "        cluster_proj_points.append(nearest_projection)\n",
    "        cluster_to_bone_map[cluster_idx].add(nearest_edge_idx)\n",
    "        bone_to_cluster_map[nearest_edge_idx].add(cluster_idx)\n",
    "    projection_points.append(cluster_proj_points)\n",
    "    projection_indices.append([nearest_edge_idx for _ in corners])\n",
    "\n",
    "# 输出 AABB 和投影点的 OBJ 文件\n",
    "output_obj_file = os.path.join(regist_dir, \"aabb_projections.obj\")\n",
    "with open(output_obj_file, 'w') as f:\n",
    "    vertex_idx = 1\n",
    "    for cluster_idx, (corners, proj_points) in enumerate(zip(aabb_corners, projection_points)):\n",
    "        corner_indices = []\n",
    "        proj_indices = []\n",
    "        for corner in corners:\n",
    "            f.write(f\"v {corner[0]} {corner[1]} {corner[2]}\\n\")\n",
    "            corner_indices.append(vertex_idx)\n",
    "            vertex_idx += 1\n",
    "        for proj_point in proj_points:\n",
    "            f.write(f\"v {proj_point[0]} {proj_point[1]} {proj_point[2]}\\n\")\n",
    "            proj_indices.append(vertex_idx)\n",
    "            vertex_idx += 1\n",
    "        # 写入AABB的12条边\n",
    "        edges = [\n",
    "            (0, 1), (1, 3), (3, 2), (2, 0),  # Bottom face\n",
    "            (4, 5), (5, 7), (7, 6), (6, 4),  # Top face\n",
    "            (0, 4), (1, 5), (2, 6), (3, 7)   # Side edges\n",
    "        ]\n",
    "        for edge in edges:\n",
    "            f.write(f\"l {corner_indices[edge[0]]} {corner_indices[edge[1]]}\\n\")\n",
    "        # 写入角点到投影点的连线\n",
    "        for i in range(len(corners)):\n",
    "            f.write(f\"l {corner_indices[i]} {proj_indices[i]}\\n\")\n",
    "            \n",
    "print(f\"AABB and projections saved to {output_obj_file}\")\n",
    "\n",
    "# 输出 CSV 文件\n",
    "cluster_to_bone_csv = os.path.join(regist_dir, \"cluster_to_bone.csv\")\n",
    "with open(cluster_to_bone_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        writer.writerow([cluster_idx] + list(cluster_to_bone_map[cluster_idx]))\n",
    "print(f\"Cluster to bone map saved to {cluster_to_bone_csv}\")\n",
    "\n",
    "bone_to_cluster_csv = os.path.join(regist_dir, \"bone_to_cluster.csv\")\n",
    "with open(bone_to_cluster_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for bone_idx in range(len(skeleton_edges)):\n",
    "        writer.writerow([bone_idx] + list(bone_to_cluster_map[bone_idx]))\n",
    "print(f\"Bone to cluster map saved to {bone_to_cluster_csv}\")\n"
   ],
   "id": "dc792dfd4ab027e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clusters_adjacent(cluster1, cluster2):\n",
    "    common_vertices = set(cluster1).intersection(set(cluster2))\n",
    "    return len(common_vertices) > 0\n",
    "\n",
    "# 计算并输出邻接关系 CSV 文件\n",
    "neighbor_csv = os.path.join(regist_dir, \"cluster_neighbor.csv\")\n",
    "neighbors = defaultdict(list)\n",
    "\n",
    "for i in range(num_clusters):\n",
    "    for j in range(i + 1, num_clusters):\n",
    "        if clusters_adjacent(cluster_vertices_list[i], cluster_vertices_list[j]):\n",
    "            neighbors[i].append(j)\n",
    "            neighbors[j].append(i)\n",
    "\n",
    "with open(neighbor_csv, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for cluster_idx in range(num_clusters):\n",
    "        writer.writerow([cluster_idx] + neighbors[cluster_idx])\n",
    "print(f\"Cluster neighbors saved to {neighbor_csv}\")"
   ],
   "id": "1a7b30d90f54404d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import igl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from sklearn.cluster import KMeans\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "# 定义文件路径\n",
    "input_file = os.path.join(\"data\", \"plane5mm.obj\")\n",
    "\n",
    "# 读取 OBJ 文件\n",
    "V, F = igl.read_triangle_mesh(input_file)\n",
    "\n",
    "# 使用 KMeans 进行聚类 (假设我们想要 200 个 cluster)\n",
    "num_clusters = 24\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "face_centers = np.mean(V[F], axis=1)\n",
    "kmeans.fit(face_centers)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# 找到每个顶点的相邻三角形\n",
    "vertex_faces = defaultdict(set)\n",
    "for i, face in enumerate(F):\n",
    "    for vertex in face:\n",
    "        vertex_faces[vertex].add(i)\n",
    "\n",
    "# 计算每个 cluster 的重心\n",
    "cluster_centroids = []\n",
    "for i in range(num_clusters):\n",
    "    cluster_vertices = V[F[labels == i]].reshape(-1, 3)\n",
    "    centroid = np.mean(cluster_vertices, axis=0)\n",
    "    cluster_centroids.append(centroid)\n",
    "\n",
    "cluster_centroids = np.array(cluster_centroids)\n",
    "\n",
    "# 计算 Morton 编码\n",
    "def interleave_bits(x, y, z):\n",
    "    def split_by_3(x):\n",
    "        x = (x | (x << 16)) & 0x030000FF\n",
    "        x = (x | (x << 8)) & 0x0300F00F\n",
    "        x = (x | (x << 4)) & 0x030C30C3\n",
    "        x = (x | (x << 2)) & 0x09249249\n",
    "        return x\n",
    "    return split_by_3(x) | (split_by_3(y) << 1) | (split_by_3(z) << 2)\n",
    "\n",
    "morton_codes = [interleave_bits(int(c[0]*1024), int(c[1]*1024), int(c[2]*1024)) for c in cluster_centroids]\n",
    "sorted_indices = np.argsort(morton_codes)\n",
    "\n",
    "# 输出目录\n",
    "output_dir = \"output_clusters\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 准备CSV数据\n",
    "cluster_vertices_list = []\n",
    "extended_cluster_vertices_list = []\n",
    "\n",
    "# 将每个 cluster 及其扩展层保存为新的 OBJ 文件\n",
    "for sorted_idx, idx in enumerate(sorted_indices):\n",
    "    cluster_faces = F[labels == idx]\n",
    "    cluster_vertices_indices = np.unique(cluster_faces)\n",
    "    cluster_vertices = V[cluster_vertices_indices]\n",
    "\n",
    "    new_indices = {old_idx: new_idx for new_idx, old_idx in enumerate(cluster_vertices_indices)}\n",
    "    cluster_faces_new = np.vectorize(new_indices.get)(cluster_faces)\n",
    "\n",
    "    # 保存聚类的原始OBJ\n",
    "    output_filename = os.path.join(output_dir, f\"cluster_{sorted_idx}.obj\")\n",
    "    igl.write_triangle_mesh(output_filename, cluster_vertices, cluster_faces_new)\n",
    "    print(f\"Cluster {sorted_idx} saved to {output_filename}\")\n",
    "\n",
    "    # 保存聚类内的顶点索引到列表\n",
    "    cluster_vertices_list.append(cluster_vertices_indices)\n",
    "\n",
    "    # 找到扩展层的三角形\n",
    "    extended_faces = set()\n",
    "    for face_idx in np.where(labels == idx)[0]:\n",
    "        # 找到所有与该face共享顶点的三角形\n",
    "        for vertex in F[face_idx]:\n",
    "            extended_faces.update(vertex_faces[vertex])\n",
    "    extended_faces.difference_update(np.where(labels == idx)[0])  # 移除原始聚类的三角形\n",
    "    extended_faces = np.array(list(extended_faces))\n",
    "\n",
    "    if len(extended_faces) > 0:\n",
    "        extended_cluster_faces = F[extended_faces]\n",
    "        extended_cluster_vertices_indices = np.unique(extended_cluster_faces)\n",
    "        extended_cluster_vertices = V[extended_cluster_vertices_indices]\n",
    "\n",
    "        new_indices_ext = {old_idx: new_idx for new_idx, old_idx in enumerate(extended_cluster_vertices_indices)}\n",
    "        extended_cluster_faces_new = np.vectorize(new_indices_ext.get)(extended_cluster_faces)\n",
    "\n",
    "        # 保存扩展层的OBJ\n",
    "        extended_output_filename = os.path.join(output_dir, f\"extended_cluster_{sorted_idx}.obj\")\n",
    "        igl.write_triangle_mesh(extended_output_filename, extended_cluster_vertices, extended_cluster_faces_new)\n",
    "        print(f\"Extended Cluster {sorted_idx} saved to {extended_output_filename}\")\n",
    "\n",
    "        # 保存扩展层顶点索引到列表\n",
    "        extended_cluster_vertices_list.append(np.unique(np.concatenate((cluster_vertices_indices, extended_cluster_vertices_indices))))\n",
    "    else:\n",
    "        print(f\"No extended faces found for cluster {sorted_idx}\")\n",
    "        # 如果没有扩展层，则仅保存原始聚类的顶点索引\n",
    "        extended_cluster_vertices_list.append(cluster_vertices_indices)\n",
    "\n",
    "# 导出聚类顶点索引的CSV文件\n",
    "cluster_vertices_file = os.path.join(output_dir, \"cluster_vertices.csv\")\n",
    "with open(cluster_vertices_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for indices in cluster_vertices_list:\n",
    "        writer.writerow(indices)\n",
    "print(f\"Cluster vertices saved to {cluster_vertices_file}\")\n",
    "\n",
    "# 导出扩展层顶点索引的CSV文件\n",
    "extended_cluster_vertices_file = os.path.join(output_dir, \"extended_cluster_vertices.csv\")\n",
    "with open(extended_cluster_vertices_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for indices in extended_cluster_vertices_list:\n",
    "        writer.writerow(indices)\n",
    "print(f\"Extended cluster vertices saved to {extended_cluster_vertices_file}\")\n"
   ],
   "id": "b3b11b9939f4cf00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5d8ebd32aa7486d3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
